{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd359529",
   "metadata": {},
   "source": [
    "# spam detection system using Python, the Natural Language Toolkit (NLTK), and the Scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925512c",
   "metadata": {},
   "source": [
    "## summary of the spam detection model:\n",
    "\n",
    "1. Data Loading: The model begins by loading the SMS Spam Collection dataset, which consists of SMS messages labeled as either 'ham' (not spam) or 'spam'.\n",
    "\n",
    "2. Data Preparation: The labels are mapped to binary values, with 'ham' as 0 and 'spam' as 1.\n",
    "\n",
    "3. Data Splitting: The dataset is split into a training set and a testing set. 80% of the data is used for training the model, and 20% is used for testing its performance.\n",
    "\n",
    "4. Vectorization: The texts of the SMS messages are vectorized using the CountVectorizer from Scikit-learn. This transforms the text into a matrix of token counts, which can be used as input for the machine learning model.\n",
    "\n",
    "5. Model Training: A Multinomial Naive Bayes classifier is trained on the training data. This is a suitable model for classification with discrete features (like word counts).\n",
    "\n",
    "6. Prediction: The trained model is used to predict the labels (i.e., whether a message is 'ham' or 'spam') for the test set.\n",
    "\n",
    "7. Evaluation: Finally, the performance of the model is evaluated by comparing the predicted labels to the true labels. The classification report includes metrics like precision, recall, and F1-score for both the 'ham' and 'spam' classes, as well as the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc5ac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       970\n",
      "           1       0.98      0.93      0.95       145\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])\n",
    "\n",
    "# Map the label to a binary variable\n",
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2)\n",
    "\n",
    "# Vectorize the texts\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = classifier.predict(X_test_transformed)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedee591",
   "metadata": {},
   "source": [
    "## The output you're seeing is a classification report, which is a summary of the performance of a classification model on the test data. Here's what each term means in the context of your spam detection system:\n",
    "\n",
    "- Precision: This is the ratio of true positives (the number of items correctly labeled as belonging to the positive class) to the sum of true positives and false positives (the number of items incorrectly labeled as belonging to the positive class). In your case, the precision for the 'ham' class (0) is 0.99 and for the 'spam' class (1) is 0.98. This means that 99% of the messages that the model labeled as 'ham' were actually 'ham', and 98% of the messages that the model labeled as 'spam' were actually 'spam'.\n",
    "\n",
    "- Recall: This is the ratio of true positives to the sum of true positives and false negatives (the number of items incorrectly labeled as belonging to the negative class). In your case, the recall for the 'ham' class is 1.00 and for the 'spam' class is 0.93. This means that the model correctly identified 100% of the 'ham' messages and 93% of the 'spam' messages.\n",
    "\n",
    "- F1-score: This is the harmonic mean of precision and recall. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. In your case, the F1 score for the 'ham' class is 0.99 and for the 'spam' class is 0.95, which is quite good.\n",
    "\n",
    "- Support: This is the number of occurrences of each class in the true data. In your case, there were 970 'ham' messages and 145 'spam' messages in the test data.\n",
    "\n",
    "- Macro avg: This is the average of the metric for each class without considering the proportion of each class in the true data.\n",
    "\n",
    "- Weighted avg: This is the average of the metric for each class considering the proportion of each class in the true data.\n",
    "\n",
    "- Accuracy: This is the ratio of the total number of correct predictions to the total number of predictions. In your case, the accuracy of the model is 0.99, which means that the model correctly predicted the class of 99% of the messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
